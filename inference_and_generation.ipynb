{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "591462b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cephfs/users/bashir/RCoT-Diffusion-LLM/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0\n"
     ]
    }
   ],
   "source": [
    "from inference_and_generation import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72c02283",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 104.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating 5 examples\n",
      "Model type: Base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (total samples: 5):   0%|          | 0/3 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Evaluating (total samples: 5):  33%|███▎      | 1/3 [00:14<00:28, 14.46s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Evaluating (total samples: 5):  67%|██████▋   | 2/3 [00:30<00:15, 15.58s/it]The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Evaluating (total samples: 5): 100%|██████████| 3/3 [00:34<00:00, 11.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved generations to results/Qwen_Qwen2.5-7B-base_256_0_2_0.0_generations_ar.json\n",
      "CPU times: user 35.1 s, sys: 11.5 s, total: 46.6 s\n",
      "Wall time: 55.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_name = \"Qwen/Qwen2.5-7B\"\n",
    "data = \"gsm8k\"\n",
    "num_evals_to_use = 5\n",
    "few_shot = 0\n",
    "batch_size = 2\n",
    "gen_length = 256\n",
    "temperature = 0.0\n",
    "top_p = 0.95\n",
    "n_samples = 2\n",
    "\n",
    "metrics = evaluate_auto_regressive_model(\n",
    "    model_name, data, num_evals_to_use, few_shot, batch_size, gen_length, temperature, top_p, n_samples\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c40e75b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 6/6 [00:00<00:00, 176.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating 5 examples\n",
      "Model type: Base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (total samples: 5): 100%|██████████| 3/3 [00:18<00:00,  6.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved generations to results/GSAI-ML_LLaDA-8B-Base_256_32_0_2_0.0_generations_testing.json\n",
      "CPU times: user 22.3 s, sys: 13.3 s, total: 35.6 s\n",
      "Wall time: 39.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "diffusion_model_name = \"GSAI-ML/LLaDA-8B-Base\"\n",
    "data = \"gsm8k\"\n",
    "num_evals_to_use = 5\n",
    "few_shot = 0\n",
    "batch_size = 2\n",
    "gen_length = 256\n",
    "diffusion_steps = 32\n",
    "temperature = 0.0\n",
    "cfg_scale = 0.0\n",
    "steps = 32\n",
    "block_length = 32\n",
    "remasking = \"low_confidence\"\n",
    "alg = \"entropy\"\n",
    "alg_temp = 0.0\n",
    "top_p = 0.95\n",
    "top_k = None\n",
    "n_samples = 2\n",
    "\n",
    "metrics = evaluate_dllm(\n",
    "    diffusion_model_name, data, num_evals_to_use, few_shot, batch_size, gen_length, diffusion_steps, temperature, cfg_scale, steps, block_length, remasking, alg, alg_temp, top_p, top_k, n_samples\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1233016",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 6/6 [00:00<00:00, 174.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating 5 examples\n",
      "Model type: Base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (total samples: 5): 100%|██████████| 3/3 [00:37<00:00, 12.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved generations to results/GSAI-ML_LLaDA-8B-Base_256_64_0_2_0.0_generations_testing.json\n",
      "CPU times: user 39.2 s, sys: 15.4 s, total: 54.5 s\n",
      "Wall time: 58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "diffusion_model_name = \"GSAI-ML/LLaDA-8B-Base\"\n",
    "data = \"gsm8k\"\n",
    "num_evals_to_use = 5\n",
    "few_shot = 0\n",
    "batch_size = 2\n",
    "gen_length = 256\n",
    "diffusion_steps = 64\n",
    "temperature = 0.0\n",
    "cfg_scale = 0.0\n",
    "steps = 64\n",
    "block_length = 32\n",
    "remasking = \"low_confidence\"\n",
    "alg = \"entropy\"\n",
    "alg_temp = 0.0\n",
    "top_p = 0.95\n",
    "top_k = None\n",
    "n_samples = 2\n",
    "\n",
    "metrics = evaluate_dllm(\n",
    "    diffusion_model_name, data, num_evals_to_use, few_shot, batch_size, gen_length, diffusion_steps, temperature, cfg_scale, steps, block_length, remasking, alg, alg_temp, top_p, top_k, n_samples\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd1e4542",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 6/6 [00:00<00:00, 174.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating 5 examples\n",
      "Model type: Base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (total samples: 5): 100%|██████████| 3/3 [02:27<00:00, 49.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved generations to results/GSAI-ML_LLaDA-8B-Base_256_256_0_2_0.0_generations_testing.json\n",
      "CPU times: user 2min 17s, sys: 25.8 s, total: 2min 43s\n",
      "Wall time: 2min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "diffusion_model_name = \"GSAI-ML/LLaDA-8B-Base\"\n",
    "data = \"gsm8k\"\n",
    "num_evals_to_use = 5\n",
    "few_shot = 0\n",
    "batch_size = 2\n",
    "gen_length = 256\n",
    "diffusion_steps = 256\n",
    "temperature = 0.0\n",
    "cfg_scale = 0.0\n",
    "steps = 256\n",
    "block_length = 32\n",
    "remasking = \"low_confidence\"\n",
    "alg = \"entropy\"\n",
    "alg_temp = 0.0\n",
    "top_p = 0.95\n",
    "top_k = None\n",
    "n_samples = 2\n",
    "device = \"cuda\"\n",
    "output_dir = \"results\"\n",
    "\n",
    "metrics = evaluate_dllm(\n",
    "    diffusion_model_name, data, num_evals_to_use, few_shot, batch_size, gen_length, diffusion_steps, temperature, cfg_scale, steps, block_length, remasking, alg, alg_temp, top_p, top_k, n_samples, device, output_dir\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69071d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 6/6 [00:00<00:00, 169.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating 5 examples\n",
      "Model type: Base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (total samples: 5): 100%|██████████| 3/3 [00:23<00:00,  7.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved generations to results/GSAI-ML_LLaDA-8B-Base_256_256_0_2_0.0_generations_testing_fast_dllm.json\n",
      "CPU times: user 25.9 s, sys: 11.6 s, total: 37.6 s\n",
      "Wall time: 42.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "diffusion_model_name = \"GSAI-ML/LLaDA-8B-Base\"\n",
    "data = \"gsm8k\"\n",
    "num_evals_to_use = 5\n",
    "few_shot = 0\n",
    "batch_size = 2\n",
    "gen_length = 256\n",
    "diffusion_steps = 256\n",
    "temperature = 0.0\n",
    "cfg_scale = 0.0\n",
    "steps = 256\n",
    "block_length = 32\n",
    "remasking = \"low_confidence\"\n",
    "alg = \"entropy\"\n",
    "alg_temp = 0.0\n",
    "top_p = 0.95\n",
    "top_k = None\n",
    "n_samples = 2\n",
    "use_cache=True\n",
    "dual_cache=True\n",
    "threshold = 0.3\n",
    "factor = 1.0\n",
    "\n",
    "metrics = evaluate_fast_dllm(\n",
    "    diffusion_model_name, data, num_evals_to_use, few_shot, batch_size, gen_length, diffusion_steps, temperature, cfg_scale, steps, block_length, remasking, alg, alg_temp, top_p, top_k, n_samples, use_cache, dual_cache, threshold, factor\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33941ff4",
   "metadata": {},
   "source": [
    "\n",
    "## Results Summary Table\n",
    "\n",
    "| # | Method | Model | Steps | Gen Length | Block | Wall Time (s) | Time/Sample (s) | Time/Generation (s) | Throughput (gen/s) | Output Quality | Status |\n",
    "|---|--------|-------|-------|------------|-------|---------------|-----------------|---------------------|-------------------|----------------|--------|\n",
    "| 1 | **Official LLaDA** | LLaDA-8B-Base | **256** | 256 | 32 | 49.05 | 4.90 | 2.45 | 0.41 | ✅ **Excellent** | **WORKING** |\n",
    "| 2 | **Fast-dLLM** | LLaDA-8B-Base | 256 | 256 | 32 | 7.90 | 0.79 | 0.40 | 2.53 | ⚠️ Good | Minor Issues |\n",
    "| 3 | **Official LLaDA** | LLaDA-8B-Base | 64 | 256 | 32 | 12.58 | 1.26 | 0.63 | 1.59 | ❌ Failed | Zeros/incomplete |\n",
    "| 4 | **Official LLaDA** | LLaDA-8B-Base | 32 | 256 | 32 | 6.09 | 0.61 | 0.30 | 3.28 | ❌ Failed | Completely garbled |\n",
    "| 5 | **Autoregressive** | Qwen2.5-7B | N/A | 256 | N/A | 11.37 | 1.14 | 0.57 | 1.76 | ✅ **Excellent** | **WORKING** |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6cc1af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating 5 examples\n",
      "Model type: Base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (total samples: 5): 100%|██████████| 3/3 [00:13<00:00,  4.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved generations to results/Dream-org_Dream-v0-Base-7B_256_32_0_2_0.0_generations_testing.json\n",
      "CPU times: user 16.7 s, sys: 17.1 s, total: 33.8 s\n",
      "Wall time: 51.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "diffusion_model_name = \"Dream-org/Dream-v0-Base-7B\"\n",
    "data = \"gsm8k\"\n",
    "num_evals_to_use = 5\n",
    "few_shot = 0\n",
    "batch_size = 2\n",
    "gen_length = 256\n",
    "diffusion_steps = 32\n",
    "temperature = 0.0\n",
    "cfg_scale = 0.0\n",
    "steps = 32\n",
    "block_length = 32\n",
    "remasking = \"low_confidence\"\n",
    "alg = \"entropy\"\n",
    "alg_temp = 0.0\n",
    "top_p = 0.95\n",
    "top_k = None\n",
    "n_samples = 2\n",
    "\n",
    "metrics = evaluate_dllm(\n",
    "    diffusion_model_name, data, num_evals_to_use, few_shot, batch_size, gen_length, diffusion_steps, temperature, cfg_scale, steps, block_length, remasking, alg, alg_temp, top_p, top_k, n_samples\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0876ec25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 102.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating 5 examples\n",
      "Model type: Base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (total samples: 5): 100%|██████████| 3/3 [00:30<00:00, 10.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved generations to results/Dream-org_Dream-v0-Base-7B_256_64_0_2_0.0_generations_testing.json\n",
      "CPU times: user 32.5 s, sys: 9.74 s, total: 42.2 s\n",
      "Wall time: 46.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "diffusion_model_name = \"Dream-org/Dream-v0-Base-7B\"\n",
    "data = \"gsm8k\"\n",
    "num_evals_to_use = 5\n",
    "few_shot = 0\n",
    "batch_size = 2\n",
    "gen_length = 256\n",
    "diffusion_steps = 64\n",
    "temperature = 0.0\n",
    "cfg_scale = 0.0\n",
    "steps = 64\n",
    "block_length = 32\n",
    "remasking = \"low_confidence\"\n",
    "alg = \"entropy\"\n",
    "alg_temp = 0.0\n",
    "top_p = 0.95\n",
    "top_k = None\n",
    "n_samples = 2\n",
    "\n",
    "metrics = evaluate_dllm(\n",
    "    diffusion_model_name, data, num_evals_to_use, few_shot, batch_size, gen_length, diffusion_steps, temperature, cfg_scale, steps, block_length, remasking, alg, alg_temp, top_p, top_k, n_samples\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86e14d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 95.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating 5 examples\n",
      "Model type: Base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (total samples: 5): 100%|██████████| 3/3 [01:59<00:00, 39.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved generations to results/Dream-org_Dream-v0-Base-7B_256_256_0_2_0.0_generations_testing.json\n",
      "CPU times: user 2min 1s, sys: 10.8 s, total: 2min 12s\n",
      "Wall time: 2min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "diffusion_model_name = \"Dream-org/Dream-v0-Base-7B\"\n",
    "data = \"gsm8k\"\n",
    "num_evals_to_use = 5\n",
    "few_shot = 0\n",
    "batch_size = 2\n",
    "gen_length = 256\n",
    "diffusion_steps = 256\n",
    "temperature = 0.0\n",
    "cfg_scale = 0.0\n",
    "steps = 256\n",
    "block_length = 32\n",
    "remasking = \"low_confidence\"\n",
    "alg = \"entropy\"\n",
    "alg_temp = 0.0\n",
    "top_p = 0.95\n",
    "top_k = None\n",
    "n_samples = 2\n",
    "\n",
    "metrics = evaluate_dllm(\n",
    "    diffusion_model_name, data, num_evals_to_use, few_shot, batch_size, gen_length, diffusion_steps, temperature, cfg_scale, steps, block_length, remasking, alg, alg_temp, top_p, top_k, n_samples\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356d8eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 99.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating 5 examples\n",
      "Model type: Base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (total samples: 5): 100%|██████████| 5/5 [00:33<00:00,  6.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved generations to results/Dream-org_Dream-v0-Base-7B_256_256_0_2_0.0_generations_testing_fast_dllm.json\n",
      "CPU times: user 35.2 s, sys: 9.64 s, total: 44.9 s\n",
      "Wall time: 49.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "diffusion_model_name = \"Dream-org/Dream-v0-Base-7B\"\n",
    "data = \"gsm8k\"\n",
    "num_evals_to_use = 5\n",
    "few_shot = 0\n",
    "batch_size = 1\n",
    "gen_length = 256\n",
    "diffusion_steps = 256\n",
    "temperature = 0.0\n",
    "cfg_scale = 0.0\n",
    "steps = 256\n",
    "block_length = 32\n",
    "remasking = \"low_confidence\"\n",
    "alg = \"confidence_threshold\"\n",
    "alg_temp = 0.0\n",
    "top_p = 0.95\n",
    "top_k = None\n",
    "n_samples = 2\n",
    "use_cache=True\n",
    "dual_cache=True\n",
    "threshold = 0.75\n",
    "factor = 1.0\n",
    "\n",
    "metrics = evaluate_fast_dllm(\n",
    "    diffusion_model_name, data, num_evals_to_use, few_shot, batch_size, gen_length, diffusion_steps, temperature, cfg_scale, steps, block_length, remasking, alg, alg_temp, top_p, top_k, n_samples, use_cache, dual_cache, threshold, factor\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88ca23f",
   "metadata": {},
   "source": [
    "## Results Summary Table (End-to-End Times)\n",
    "\n",
    "| # | Method | Model | Steps | Temp | Block | Cache | Alg | Wall Time (s) | Time/Sample (s) | Time/Gen (s) | Throughput (tok/s) | Output Quality | Status |\n",
    "|---|--------|-------|-------|------|-------|-------|-----|---------------|-----------------|-----------------|-------------------|----------------|--------|\n",
    "| 1 | **Dream Official** | Dream-7B | 256 | 0.0 | N/A | ❌ No | entropy | **138.0s** | 13.80 | 6.90 | 37.1 tok/s | ⚠️ Mixed | Incomplete |\n",
    "| 2 | **Dream Official** | Dream-7B | 64 | 0.0 | N/A | ❌ No | entropy | **46.8s** | 4.68 | 2.34 | 109.4 tok/s | ⚠️ Mixed | Incomplete |\n",
    "| 3 | **Dream Official** | Dream-7B | 32 | 0.0 | N/A | ❌ No | entropy | **51.3s** | 5.13 | 2.57 | 99.9 tok/s | ❌ Failed | Loading overhead |\n",
    "| 4 | **Fast-dLLM** | Dream-7B | 256 | 0.0 | 32 | ✅ Dual | entropy | **49.6s** | 4.96 | 2.48 | 103.2 tok/s | ❌ Poor | Mask tokens |\n",
    "| 5 | **Autoregressive** | Qwen-7B | N/A | 0.0 | N/A | ❌ No | N/A | **55.6s** | 5.56 | 2.78 | 92.1 tok/s | ✅ **Perfect** | **WORKING** |\n",
    "\n",
    "**Note**: These are end-to-end times including model loading overhead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1917c31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 103.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 4 few-shot examples\n",
      "evaluating 256 examples\n",
      "Model type: Base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating (total samples: 256):  28%|██▊       | 72/256 [06:47<18:23,  6.00s/it]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "diffusion_model_name = \"Dream-org/Dream-v0-Base-7B\"\n",
    "data = \"gsm8k\"\n",
    "num_evals_to_use = 256\n",
    "few_shot = 4\n",
    "batch_size = 1\n",
    "gen_length = 256\n",
    "diffusion_steps = 256\n",
    "temperature = 0.0\n",
    "cfg_scale = 0.0\n",
    "steps = 256\n",
    "block_length = 32\n",
    "remasking = \"low_confidence\"\n",
    "alg = \"confidence_threshold\"\n",
    "alg_temp = 0.0\n",
    "top_p = 0.95\n",
    "top_k = None\n",
    "n_samples = 1\n",
    "use_cache=True\n",
    "dual_cache=True\n",
    "threshold = 0.75\n",
    "factor = 1.0\n",
    "\n",
    "metrics = evaluate_fast_dllm(\n",
    "    diffusion_model_name, data, num_evals_to_use, few_shot, batch_size, gen_length, diffusion_steps, temperature, cfg_scale, steps, block_length, remasking, alg, alg_temp, top_p, top_k, n_samples, use_cache, dual_cache, threshold, factor\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
